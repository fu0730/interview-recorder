import { Audio, InterruptionModeAndroid, InterruptionModeIOS } from "expo-av";
import * as FileSystem from "expo-file-system";
import * as Speech from "expo-speech";
import { useRef, useState } from "react";
import { Alert, Button, Text, View } from "react-native";
import { BASE_QUESTIONS } from "../../constants/questions";

export default function Home() {
  const recordingRef = useRef<Audio.Recording | null>(null);
  const [uri, setUri] = useState<string | null>(null);
  const [status, setStatus] = useState("å¾…æ©Ÿä¸­");
  const [started, setStarted] = useState(false);
  const [qIndex, setQIndex] = useState(0);
  const speakAndRecord = async () => {
    try {
      const text = BASE_QUESTIONS[qIndex]?.text ?? "";
      if (!text) return;
      setStatus("è³ªå•ã‚’èª­ã¿ä¸Šã’ä¸­â€¦");
      await new Promise<void>((resolve) => {
        Speech.speak(text, { language: "ja-JP", rate: 1.0, onDone: resolve });
      });
      // èª­ã¿ä¸Šã’å¾Œã«è‡ªå‹•ã§éŒ²éŸ³é–‹å§‹
      await start();
    } catch (e: any) {
      Alert.alert("èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼", e?.message ?? String(e));
    }
  };

  const API_BASE = "https://whisper-proxy-bcxn.vercel.app"; // Vercelã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸä¸­ç¶™APIã®ãƒ™ãƒ¼ã‚¹URLï¼ˆhttpså¿…é ˆï¼‰

  const start = async () => {
    try {
      setStatus("æ¨©é™ç¢ºèªä¸­â€¦");
      const perm = await Audio.requestPermissionsAsync();
      if (!perm.granted) {
        Alert.alert("ãƒã‚¤ã‚¯æ¨©é™ãŒå¿…è¦ã§ã™");
        return;
      }
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        interruptionModeIOS: InterruptionModeIOS.DoNotMix,
        interruptionModeAndroid: InterruptionModeAndroid.DoNotMix,
        staysActiveInBackground: false,
        shouldDuckAndroid: true,
      });

      const rec = new Audio.Recording();
      await rec.prepareToRecordAsync({
        // Crossâ€‘platform: m4a(AAC) 44.1kHz / 128kbps
        android: {
          extension: ".m4a",
          outputFormat: Audio.AndroidOutputFormat.MPEG_4,
          audioEncoder: Audio.AndroidAudioEncoder.AAC,
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
        },
        ios: {
          // Use m4a(AAC) instead of CAF/PCM for Whisperäº’æ› & å°ã•ã‚ã‚µã‚¤ã‚º
          extension: ".m4a",
          audioQuality: Audio.IOSAudioQuality.HIGH,
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
          // linearPCMç³»ã¯ä½¿ã‚ãªã„ï¼ˆCAF/PCMã«ãªã‚Šå®¹é‡â†‘ï¼‰
        },
        web: {
          // Expo Webã¯MediaRecorderã‚’åˆ©ç”¨ï¼ˆå‚è€ƒè¨­å®šï¼‰
          mimeType: "audio/webm",
          bitsPerSecond: 128000,
        },
      });
      await rec.startAsync();

      recordingRef.current = rec;
      setStatus("éŒ²éŸ³ä¸­â€¦");
    } catch (e: any) {
      Alert.alert("éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼", e?.message ?? String(e));
    }
  };

  const stop = async () => {
    try {
      const rec = recordingRef.current;
      if (!rec) return;
      setStatus("åœæ­¢å‡¦ç†ä¸­â€¦");
      await rec.stopAndUnloadAsync();
      const localUri = rec.getURI();
      setUri(localUri ?? null);
      recordingRef.current = null;
      setStatus("éŒ²éŸ³å®Œäº†");
    } catch (e: any) {
      Alert.alert("åœæ­¢ã‚¨ãƒ©ãƒ¼", e?.message ?? String(e));
    }
  };

  const play = async () => {
    try {
      if (!uri) return;
      const { sound } = await Audio.Sound.createAsync({ uri });
      await sound.playAsync();
    } catch (e: any) {
      Alert.alert("å†ç”Ÿã‚¨ãƒ©ãƒ¼", e?.message ?? String(e));
    }
  };

  const upload = async () => {
    if (!uri) return;
    try {
      setStatus("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­â€¦");

      const res = await FileSystem.uploadAsync(
        `${API_BASE}/api/transcribe`,
        uri,
        {
          httpMethod: "POST",
          // @ts-ignore Expo SDK variations: FileSystemUploadType may be on the default export
          uploadType: (FileSystem as any).FileSystemUploadType?.MULTIPART ?? 1,
          fieldName: "file",          // â† ã‚µãƒ¼ãƒå´ã® formidable ã® files.file ã«å…¥ã‚‹
          mimeType: "audio/m4a",      // â† éŒ²éŸ³è¨­å®šã«åˆã‚ã›ã‚‹
        }
      );

      if (res.status !== 200) {
        throw new Error(`HTTP ${res.status}: ${res.body}`);
      }

      const data = JSON.parse(res.body);
      setStatus(`æ–‡å­—èµ·ã“ã—: ${data.text ?? ""}`);
    } catch (e: any) {
      setStatus(`ã‚¨ãƒ©ãƒ¼: ${e?.message ?? String(e)}`);
    }
  };

  return (
    <View style={{ padding: 24, gap: 12 }}>
      <Text style={{ fontSize: 20, fontWeight: "600" }}>ğŸ™ï¸ éŒ²éŸ³ãƒ†ã‚¹ãƒˆ</Text>
      {!started ? (
        <Button
          title="â–¶ï¸ ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼é–‹å§‹ï¼ˆQ1ï¼‰"
          onPress={async () => {
            setStarted(true);
            setQIndex(0);
            await speakAndRecord();
          }}
        />
      ) : (
        <Text>ã„ã¾ã®è³ªå•ï¼š{BASE_QUESTIONS[qIndex]?.text}</Text>
      )}
      <Button title="â–¶ï¸ éŒ²éŸ³é–‹å§‹" onPress={start} />
      <Button title="â¹ï¸ éŒ²éŸ³åœæ­¢" onPress={stop} />
      <Button title="ğŸ§ å†ç”Ÿ" onPress={play} disabled={!uri} />
      <Button title="ğŸ“¤ Whisperã¸é€ä¿¡" onPress={upload} disabled={!uri} />
      <Text style={{ marginTop: 8 }}>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼š{status}</Text>
      {uri ? <Text selectable style={{ color: "#555" }}>ä¿å­˜å…ˆ: {uri}</Text> : null}
    </View>
  );
}