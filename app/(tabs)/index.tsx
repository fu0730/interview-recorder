import { Audio, InterruptionModeAndroid, InterruptionModeIOS } from "expo-av";
import * as FileSystem from "expo-file-system/legacy";
import * as Speech from "expo-speech";
import { useRef, useState, useEffect } from "react";
import { Alert, Button, Text, View } from "react-native";
import { BASE_QUESTIONS } from "../../constants/questions";

export default function Home() {
  const recordingRef = useRef<Audio.Recording | null>(null);
  const [uri, setUri] = useState<string | null>(null);
  const [status, setStatus] = useState("å¾…æ©Ÿä¸­");
  const [started, setStarted] = useState(false);
  const [qIndex, setQIndex] = useState(0);

  const [isRecording, setIsRecording] = useState(false);
  const [isUploading, setIsUploading] = useState(false);
  const [secs, setSecs] = useState(0);
  const autoStopTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const MAX_REC_SEC = 90;

  // éŒ²éŸ³ä¸­ã®çµŒéç§’æ•°ã‚«ã‚¦ãƒ³ãƒˆ
  useEffect(() => {
    let t: ReturnType<typeof setInterval> | null = null;
    if (isRecording) {
      t = setInterval(() => setSecs((s) => s + 1), 1000);
    } else {
      setSecs(0);
    }
    return () => {
      if (t) clearInterval(t);
    };
  }, [isRecording]);

  const makeFollowup = async (base: string, answer: string) => {
    setStatus("æ·±æ˜ã‚Šç”Ÿæˆä¸­â€¦");
    const r = await fetch(`${API_BASE}/api/followup`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ base, answer }),
    });
    if (!r.ok) throw new Error(await r.text());
    const d = await r.json();
    return (d.question as string) || "ã‚‚ã†å°‘ã—å…·ä½“çš„ã«æ•™ãˆã¦ãã ã•ã„ã€‚";
  };

  const speakTextAndRecord = async (text: string) => {
    setStatus("è³ªå•ã‚’èª­ã¿ä¸Šã’ä¸­â€¦");
    await new Promise<void>((resolve) => {
      Speech.speak(text, { language: "ja-JP", rate: 1.0, onDone: resolve });
    });
    setStatus("éŒ²éŸ³ä¸­â€¦ï¼ˆæœ€å¤§90ç§’ï¼‰");
    await start();
  };
  const speakAndRecord = async () => {
    try {
      const text = BASE_QUESTIONS[qIndex]?.text ?? "";
      if (!text) return;
      setStatus("è³ªå•ã‚’èª­ã¿ä¸Šã’ä¸­â€¦");
      await new Promise<void>((resolve) => {
        Speech.speak(text, { language: "ja-JP", rate: 1.0, onDone: resolve });
      });
      // èª­ã¿ä¸Šã’å¾Œã«è‡ªå‹•ã§éŒ²éŸ³é–‹å§‹
      await start();
    } catch (e: any) {
      Alert.alert("èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼", e?.message ?? String(e));
    }
  };

  const API_BASE = "https://whisper-proxy-bcxn.vercel.app"; // Vercelã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸä¸­ç¶™APIã®ãƒ™ãƒ¼ã‚¹URLï¼ˆhttpså¿…é ˆï¼‰

  const start = async () => {
    try {
      setStatus("æ¨©é™ç¢ºèªä¸­â€¦");
      const perm = await Audio.requestPermissionsAsync();
      if (!perm.granted) {
        Alert.alert("ãƒã‚¤ã‚¯æ¨©é™ãŒå¿…è¦ã§ã™");
        return;
      }
      await Audio.setAudioModeAsync({
        allowsRecordingIOS: true,
        playsInSilentModeIOS: true,
        interruptionModeIOS: InterruptionModeIOS.DoNotMix,
        interruptionModeAndroid: InterruptionModeAndroid.DoNotMix,
        staysActiveInBackground: false,
        shouldDuckAndroid: true,
      });

      setIsRecording(true);

      const rec = new Audio.Recording();
      await rec.prepareToRecordAsync({
        // Crossâ€‘platform: m4a(AAC) 44.1kHz / 128kbps
        android: {
          extension: ".m4a",
          outputFormat: Audio.AndroidOutputFormat.MPEG_4,
          audioEncoder: Audio.AndroidAudioEncoder.AAC,
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
        },
        ios: {
          // Use m4a(AAC) instead of CAF/PCM for Whisperäº’æ› & å°ã•ã‚ã‚µã‚¤ã‚º
          extension: ".m4a",
          audioQuality: Audio.IOSAudioQuality.HIGH,
          sampleRate: 44100,
          numberOfChannels: 1,
          bitRate: 128000,
          // linearPCMç³»ã¯ä½¿ã‚ãªã„ï¼ˆCAF/PCMã«ãªã‚Šå®¹é‡â†‘ï¼‰
        },
        web: {
          // Expo Webã¯MediaRecorderã‚’åˆ©ç”¨ï¼ˆå‚è€ƒè¨­å®šï¼‰
          mimeType: "audio/webm",
          bitsPerSecond: 128000,
        },
      });
      await rec.startAsync();

      // è‡ªå‹•åœæ­¢ï¼ˆMAX_REC_SECï¼‰
      if (autoStopTimerRef.current) clearTimeout(autoStopTimerRef.current);
      autoStopTimerRef.current = setTimeout(() => {
        if (recordingRef.current) {
          stop(); // åœæ­¢å¾Œã¯è‡ªå‹•ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹
        }
      }, MAX_REC_SEC * 1000);

      recordingRef.current = rec;
      setStatus("éŒ²éŸ³ä¸­â€¦");
    } catch (e: any) {
      Alert.alert("éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼", e?.message ?? String(e));
    }
  };

  const stop = async () => {
    try {
      if (autoStopTimerRef.current) {
        clearTimeout(autoStopTimerRef.current);
        autoStopTimerRef.current = null;
      }
      const rec = recordingRef.current;
      if (!rec) return;
      setStatus("åœæ­¢å‡¦ç†ä¸­â€¦");
      await rec.stopAndUnloadAsync();
      const localUri = rec.getURI();
      const fileUri = localUri ?? null;
      setUri(fileUri);
      recordingRef.current = null;
      setIsRecording(false);
      setStatus("éŒ²éŸ³å®Œäº†");
      if (fileUri) {
        await upload(fileUri); // åœæ­¢å¾Œã«è‡ªå‹•é€ä¿¡
      }
    } catch (e: any) {
      Alert.alert("åœæ­¢ã‚¨ãƒ©ãƒ¼", e?.message ?? String(e));
    }
  };

  const play = async () => {
    try {
      if (!uri) return;
      const { sound } = await Audio.Sound.createAsync({ uri });
      await sound.playAsync();
    } catch (e: any) {
      Alert.alert("å†ç”Ÿã‚¨ãƒ©ãƒ¼", e?.message ?? String(e));
    }
  };

  const upload = async (fileUri?: string) => {
    const targetUri = fileUri ?? uri;
    if (!targetUri) return;
    try {
      setIsUploading(true);
      setStatus("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­â€¦");

      const res = await FileSystem.uploadAsync(
        `${API_BASE}/api/transcribe`,
        targetUri,
        {
          httpMethod: "POST",
          // @ts-ignore Expo SDK variations: FileSystemUploadType may be on the default export
          uploadType: (FileSystem as any).FileSystemUploadType?.MULTIPART ?? 1,
          fieldName: "file",          // â† ã‚µãƒ¼ãƒå´ã® formidable ã® files.file ã«å…¥ã‚‹
          mimeType: "audio/m4a",      // â† éŒ²éŸ³è¨­å®šã«åˆã‚ã›ã‚‹
        }
      );

      if (res.status !== 200) {
        throw new Error(`HTTP ${res.status}: ${res.body}`);
      }

      const data = JSON.parse(res.body);
      setStatus(`æ–‡å­—èµ·ã“ã—: ${data.text ?? ""}`);
      const text = data.text ?? "";
      const baseQ = BASE_QUESTIONS[qIndex]?.text ?? "";
      try {
        const follow = await makeFollowup(baseQ, text);
        await speakTextAndRecord(follow);
        setQIndex((i) => Math.min(i + 1, BASE_QUESTIONS.length - 1));
      } catch (e: any) {
        setStatus(`ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ç”Ÿæˆã‚¨ãƒ©ãƒ¼: ${e.message ?? String(e)}`);
      }
    } catch (e: any) {
      setStatus(`ã‚¨ãƒ©ãƒ¼: ${e?.message ?? String(e)}`);
    } finally {
      setIsUploading(false);
    }
  };

  return (
    <View style={{ padding: 24, gap: 12 }}>
      <Text style={{ fontSize: 20, fontWeight: "600" }}>
        ğŸ™ï¸ éŒ²éŸ³ãƒ†ã‚¹ãƒˆ {isRecording ? `ï¼ˆ${String(Math.floor(secs/60)).padStart(2,"0")}:${String(secs%60).padStart(2,"0")}ï¼‰` : ""}
      </Text>
      {!started ? (
        <Button
          title="â–¶ï¸ ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼é–‹å§‹ï¼ˆQ1ï¼‰"
          onPress={async () => {
            setStarted(true);
            setQIndex(0);
            await speakAndRecord();
          }}
          disabled={isRecording || isUploading}
        />
      ) : (
        <Text>ã„ã¾ã®è³ªå•ï¼š{BASE_QUESTIONS[qIndex]?.text}</Text>
      )}
      <Button title="â–¶ï¸ éŒ²éŸ³é–‹å§‹" onPress={() => start()} disabled={isRecording || isUploading} />
      <Button title="â¹ï¸ éŒ²éŸ³åœæ­¢" onPress={() => stop()} disabled={!isRecording || isUploading} />
      <Button title="ğŸ§ å†ç”Ÿ" onPress={() => play()} disabled={!uri || isRecording || isUploading} />
      <Button title="ğŸ“¤ Whisperã¸é€ä¿¡" onPress={() => upload()} disabled={!uri || isRecording || isUploading} />
      <Text style={{ marginTop: 8 }}>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼š{status}</Text>
      {uri ? <Text selectable style={{ color: "#555" }}>ä¿å­˜å…ˆ: {uri}</Text> : null}
    </View>
  );
}